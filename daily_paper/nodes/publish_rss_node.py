"""
RSSå‘å¸ƒèŠ‚ç‚¹ - ç”Ÿæˆå’Œæ›´æ–°RSS feed
"""

import os
import markdown
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List
from pocketflow import Node
from feedgen.feed import FeedGenerator
from daily_paper.utils.logger import logger
from daily_paper.model.arxiv_paper import ArxivPaper


class PublishRSSNode(Node):
    """RSSå‘å¸ƒèŠ‚ç‚¹ï¼Œç”Ÿæˆå’Œæ›´æ–°RSS feed"""

    def __init__(
        self,
        output_dir: str = "public",
        site_url: str = "https://your-username.github.io/daily-papers-site",
        feed_title: str = "Daily AI Papers",
        feed_description: str = "Latest papers in AI research - RAG, Knowledge Graph, and more",
        max_items: int = 100,
        custom_tag: str = "",
    ):
        super().__init__()
        self.output_dir = Path(output_dir)
        self.rss_file = self.output_dir / "rss.xml"
        self.site_url = site_url.rstrip("/")
        self.feed_title = feed_title
        self.feed_description = feed_description
        self.max_items = max_items
        self.custom_tag = custom_tag

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def prep(self, shared):
        """ä»å…±äº«å­˜å‚¨è·å–HTMLæ–‡ä»¶ä¿¡æ¯å’ŒRSSå…ƒæ•°æ®"""
        html_files = shared.get("html_files", [])
        generation_date = shared.get("html_generation_date")
        paper_manager = shared.get("paper_manager")

        if not html_files:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç”Ÿæˆçš„HTMLæ–‡ä»¶")
            return {}

        # è·å–æ‰€æœ‰æœ‰RSSå…ƒä¿¡æ¯çš„è®ºæ–‡ï¼ˆç”¨äºå¢é‡åˆå¹¶ï¼‰
        all_rss_papers = []
        if paper_manager:
            all_papers_df = paper_manager.get_all_papers()
            rss_papers_df = all_papers_df[
                (all_papers_df["rss_meta"].notna()) & 
                (all_papers_df["rss_meta"] != "")
            ].copy()
            
            if not rss_papers_df.empty:
                # æŒ‰update_timeæ’åºï¼Œæœ€æ–°çš„åœ¨å‰
                rss_papers_df = rss_papers_df.sort_values("update_time", ascending=False)
                all_rss_papers = rss_papers_df.to_dict("records")

        return {
            "html_files": html_files,
            "date": generation_date,
            "site_url": self.site_url,
            "all_rss_papers": all_rss_papers,
        }

    def exec(self, prep_res):
        """åŸºäºrss_metaå¢é‡ç”ŸæˆRSS feed"""
        all_rss_papers = prep_res.get("all_rss_papers", [])
        
        if not all_rss_papers:
            logger.warning("æ²¡æœ‰RSSå…ƒä¿¡æ¯å¯å‘å¸ƒ")
            return {"success": False}

        try:
            # åˆ›å»ºæ–°çš„RSS feed
            fg = self._create_feed()

            # åŸºäºæ‰€æœ‰rss_metaç”ŸæˆRSSæ¡ç›®ï¼ˆå·²æŒ‰update_timeæ’åºï¼‰
            total_items_added = 0
            for paper_record in all_rss_papers[:self.max_items]:  # é™åˆ¶æœ€å¤§æ¡ç›®æ•°
                if self._add_rss_item_from_meta(fg, paper_record):
                    total_items_added += 1

            # æ›´æ–°feedå…ƒæ•°æ®
            fg.lastBuildDate(datetime.now(timezone.utc))

            # ä¿å­˜RSSæ–‡ä»¶
            self._save_rss_feed(fg)

            logger.info(f"RSS feedç”Ÿæˆå®Œæˆï¼ŒåŒ…å« {total_items_added} ä¸ªæ¡ç›®")
            return {
                "success": True,
                "new_items": len(prep_res.get("html_files", [])),  # æœ¬æ¬¡æ–°å¢çš„
                "total_items": total_items_added,
                "rss_file": str(self.rss_file),
            }

        except Exception as e:
            logger.error(f"RSSç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def post(self, shared, prep_res, exec_res):
        """æ›´æ–°å…±äº«å­˜å‚¨ä¸­çš„RSSä¿¡æ¯"""
        if exec_res.get("success"):
            shared["rss_published"] = True
            shared["rss_file"] = exec_res.get("rss_file")
            shared["rss_items_count"] = exec_res.get("total_items", 0)
            logger.info("RSSå‘å¸ƒæˆåŠŸ")
        else:
            shared["rss_published"] = False
            logger.error(f"RSSå‘å¸ƒå¤±è´¥: {exec_res.get('error', 'Unknown error')}")

        return "default"

    def _create_feed(self) -> FeedGenerator:
        """åˆ›å»ºæ–°çš„RSS feed"""
        fg = FeedGenerator()

        # è®¾ç½®feedåŸºæœ¬ä¿¡æ¯
        fg.id(self.site_url)
        fg.title(self.feed_title)
        fg.link(href=self.site_url, rel="alternate")
        fg.link(href=f"{self.site_url}/rss.xml", rel="self")
        fg.description(self.feed_description)
        fg.language("zh-cn")
        fg.lastBuildDate(datetime.now(timezone.utc))
        fg.managingEditor("ai-research@example.com (AI Research Team)")
        fg.webMaster("webmaster@example.com (Webmaster)")

        return fg

    def _add_rss_item_from_meta(self, fg: FeedGenerator, paper_record: dict) -> bool:
        """åŸºäºrss_metaæ·»åŠ RSSæ¡ç›®"""
        try:
            import json
            
            # è§£æRSSå…ƒä¿¡æ¯
            rss_meta = json.loads(paper_record["rss_meta"])
            paper_id = paper_record["paper_id"]
            update_time = paper_record["update_time"]
            
            # ç”Ÿæˆæ¡ç›®å”¯ä¸€ID
            item_id = f"{self.site_url}{rss_meta['url']}"

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ¡ç›®ï¼ˆé¿å…é‡å¤ï¼‰
            for entry in fg.entry():
                if entry.id() == item_id:
                    logger.debug(f"æ¡ç›®å·²å­˜åœ¨ï¼Œè·³è¿‡: {item_id}")
                    return False

            # åˆ›å»ºæ–°çš„RSSæ¡ç›®
            fe = fg.add_entry()
            fe.id(item_id)
            fe.title(rss_meta["title"])
            fe.link(href=f"{self.site_url}{rss_meta['url']}")
            fe.description(rss_meta["description"])

            # è®¾ç½®å‘å¸ƒæ—¶é—´ï¼ˆä½¿ç”¨update_timeï¼‰
            try:
                if isinstance(update_time, str):
                    pub_date = datetime.strptime(update_time, '%Y-%m-%d')
                else:
                    pub_date = datetime.combine(update_time, datetime.min.time())
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            except:
                pub_date = datetime.now(timezone.utc)
            fe.pubDate(pub_date)

            # æ·»åŠ åˆ†ç±»
            fe.category({'term': rss_meta["category"]})
            if rss_meta["category"] != "AI Research":
                fe.category({'term': 'AI Research'})

            # æ·»åŠ å†…å®¹
            fe.content(rss_meta["content"], type="CDATA")

            logger.debug(f"æ·»åŠ RSSæ¡ç›®: {rss_meta['title']}")
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ RSSæ¡ç›®å¤±è´¥: {e}")
            return False

    def _add_paper_rss_item(self, fg: FeedGenerator, file_info: Dict) -> bool:
        """ä¸ºRSS feedæ·»åŠ å•ç¯‡è®ºæ–‡æ¡ç›®"""
        try:
            paper_title = file_info["paper_title"]
            filename = file_info["filename"]
            url = f"{self.site_url}{file_info['url']}"
            
            # ç”Ÿæˆæ¡ç›®å”¯ä¸€IDï¼ˆä½¿ç”¨paper_idç¡®ä¿å”¯ä¸€æ€§ï¼‰
            item_id = f"{self.site_url}/posts/{filename}"

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ¡ç›®
            for entry in fg.entry():
                if entry.id() == item_id:
                    logger.debug(f"æ¡ç›®å·²å­˜åœ¨ï¼Œè·³è¿‡: {item_id}")
                    return False

            # åˆ›å»ºæ–°çš„RSSæ¡ç›®
            fe = fg.add_entry()
            fe.id(item_id)
            fe.title(paper_title)
            fe.link(href=url)
            fe.description(f"{self.custom_tag or 'AI'} è®ºæ–‡: {paper_title}")

            # ç”Ÿæˆå‘å¸ƒæ—¶é—´
            try:
                pub_date = datetime.strptime(file_info["date"], '%Y-%m-%d')
                pub_date = pub_date.replace(tzinfo=timezone.utc)
            except:
                pub_date = datetime.now(timezone.utc)
            fe.pubDate(pub_date)

            # æ·»åŠ åˆ†ç±»
            if self.custom_tag:
                fe.category({'term': self.custom_tag})
            fe.category({'term': 'AI Research'})

            # æ·»åŠ è®ºæ–‡æ‘˜è¦ä½œä¸ºå†…å®¹ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            content = f"<h2>{paper_title}</h2><p>æŸ¥çœ‹å®Œæ•´çš„è®ºæ–‡åˆ†æå’Œæ‘˜è¦ã€‚</p><p><a href=\"{url}\">é˜…è¯»å…¨æ–‡</a></p>"
            fe.content(content, type="CDATA")

            logger.debug(f"æ·»åŠ RSSæ¡ç›®: {paper_title}")
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ RSSæ¡ç›®å¤±è´¥: {e}")
            return False

    def _generate_content_summary(self, file_info: Dict, papers_count: int) -> str:
        """ç”ŸæˆRSSæ¡ç›®çš„å†…å®¹æ‘˜è¦"""
        category = file_info["category"]
        date = file_info.get("date", "ä»Šæ—¥")

        summary = f"""
<h2>{category} é¢†åŸŸè®ºæ–‡æ±‡æ€»</h2>
<p>æœ¬æœŸä¸ºæ‚¨ç²¾é€‰äº† {papers_count} ç¯‡ {category} é¢†åŸŸçš„ä¼˜è´¨è®ºæ–‡ï¼Œæ¯ç¯‡éƒ½ç»è¿‡è¯¦ç»†çš„ç»“æ„åŒ–åˆ†æã€‚</p>

<h3>ä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š</h3>
<ul>
    <li>ğŸ“Š é—®é¢˜å®šä¹‰ä¸ç ”ç©¶åŠ¨æœº</li>
    <li>ğŸ” æŠ€æœ¯æ–¹æ¡ˆä¸åˆ›æ–°ç‚¹</li>
    <li>âš¡ å®éªŒéªŒè¯ä¸ç»“æœåˆ†æ</li>
    <li>ğŸ’¡ åº”ç”¨å‰æ™¯ä¸æœªæ¥å±•æœ›</li>
</ul>

<p><a href="{self.site_url}{file_info['url']}">ç‚¹å‡»æŸ¥çœ‹å®Œæ•´åˆ†æ</a></p>

<hr>
<p><em>ç”± Daily Paper Processing System è‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ¥æº: arXiv</em></p>
"""
        return summary.strip()

    def _limit_feed_items(self, fg: FeedGenerator):
        """é™åˆ¶RSS feedçš„æœ€å¤§æ¡ç›®æ•°"""
        if len(fg.entry()) > self.max_items:
            # æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„æ¡ç›®
            entries = fg.entry()
            entries.sort(key=lambda e: e.pubDate(), reverse=True)
            fg.entry(entries[: self.max_items], replace=True)
            logger.info(f"RSSæ¡ç›®å·²é™åˆ¶ä¸ºæœ€æ–° {self.max_items} æ¡")

    def _save_rss_feed(self, fg: FeedGenerator):
        """ä¿å­˜RSS feedåˆ°æ–‡ä»¶"""
        try:
            # ç”ŸæˆRSS XML
            rss_str = fg.rss_str(pretty=True)

            # å†™å…¥æ–‡ä»¶
            with open(self.rss_file, "wb") as f:
                f.write(rss_str)

            logger.info(f"RSSæ–‡ä»¶å·²ä¿å­˜: {self.rss_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜RSSæ–‡ä»¶å¤±è´¥: {e}")
            raise

    def configure_from_config(self, config: Dict[str, Any]):
        """ä»é…ç½®ä¸­æ›´æ–°RSSè®¾ç½®"""
        rss_config = config.get("rss", {})

        if "site_url" in rss_config:
            self.site_url = rss_config["site_url"].rstrip("/")

        if "title" in rss_config:
            self.feed_title = rss_config["title"]

        if "description" in rss_config:
            self.feed_description = rss_config["description"]

        if "max_items" in rss_config:
            self.max_items = rss_config["max_items"]

        logger.info(f"RSSé…ç½®å·²æ›´æ–°: {self.feed_title} @ {self.site_url}")
