"""
RSSå‘å¸ƒèŠ‚ç‚¹ - ç”Ÿæˆå’Œæ›´æ–°RSS feed
"""

import os
import markdown
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, Any, List
from pocketflow import Node
from feedgen.feed import FeedGenerator
from daily_paper.utils.logger import logger
from daily_paper.model.arxiv_paper import ArxivPaper


class PublishRSSNode(Node):
    """RSSå‘å¸ƒèŠ‚ç‚¹ï¼Œç”Ÿæˆå’Œæ›´æ–°RSS feed"""

    def __init__(
        self,
        output_dir: str = "public",
        site_url: str = "https://your-username.github.io/daily-papers-site",
        feed_title: str = "Daily AI Papers",
        feed_description: str = "Latest papers in AI research - RAG, Knowledge Graph, and more",
        max_items: int = 100,
    ):
        super().__init__()
        self.output_dir = Path(output_dir)
        self.rss_file = self.output_dir / "rss.xml"
        self.site_url = site_url.rstrip("/")
        self.feed_title = feed_title
        self.feed_description = feed_description
        self.max_items = max_items

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def prep(self, shared):
        """ä»å…±äº«å­˜å‚¨è·å–HTMLæ–‡ä»¶ä¿¡æ¯"""
        html_files = shared.get("html_files", [])
        generation_date = shared.get("html_generation_date")

        if not html_files:
            logger.warning("æ²¡æœ‰æ‰¾åˆ°ç”Ÿæˆçš„HTMLæ–‡ä»¶")
            return {}

        return {
            "html_files": html_files,
            "date": generation_date,
            "site_url": self.site_url,
        }

    def exec(self, prep_res):
        """ç”Ÿæˆæˆ–æ›´æ–°RSS feed"""
        if not prep_res.get("html_files"):
            logger.warning("æ²¡æœ‰HTMLæ–‡ä»¶å¯å‘å¸ƒåˆ°RSS")
            return {"success": False}

        html_files = prep_res["html_files"]
        date = prep_res["date"]

        try:
            # åˆ›å»ºæˆ–åŠ è½½ç°æœ‰çš„RSS feed
            fg = self._create_or_load_feed()

            # ä¸ºæ¯ä¸ªHTMLæ–‡ä»¶æ·»åŠ RSSæ¡ç›®
            new_items_added = 0
            for file_info in html_files:
                if self._add_rss_item(fg, file_info, date):
                    new_items_added += 1

            # é™åˆ¶æœ€å¤§æ¡ç›®æ•°
            self._limit_feed_items(fg)

            # æ›´æ–°feedå…ƒæ•°æ®
            fg.lastBuildDate(datetime.now(timezone.utc))

            # ä¿å­˜RSSæ–‡ä»¶
            self._save_rss_feed(fg)

            logger.info(f"RSS feedæ›´æ–°å®Œæˆï¼Œæ–°å¢ {new_items_added} ä¸ªæ¡ç›®")
            return {
                "success": True,
                "new_items": new_items_added,
                "total_items": len(fg.entry),
                "rss_file": str(self.rss_file),
            }

        except Exception as e:
            logger.error(f"RSSç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"success": False, "error": str(e)}

    def post(self, shared, prep_res, exec_res):
        """æ›´æ–°å…±äº«å­˜å‚¨ä¸­çš„RSSä¿¡æ¯"""
        if exec_res.get("success"):
            shared["rss_published"] = True
            shared["rss_file"] = exec_res.get("rss_file")
            shared["rss_items_count"] = exec_res.get("total_items", 0)
            logger.info("RSSå‘å¸ƒæˆåŠŸ")
        else:
            shared["rss_published"] = False
            logger.error(f"RSSå‘å¸ƒå¤±è´¥: {exec_res.get('error', 'Unknown error')}")

        return "default"

    def _create_or_load_feed(self) -> FeedGenerator:
        """åˆ›å»ºæˆ–åŠ è½½ç°æœ‰çš„RSS feed"""
        fg = FeedGenerator()

        # è®¾ç½®feedåŸºæœ¬ä¿¡æ¯
        fg.id(self.site_url)
        fg.title(self.feed_title)
        fg.link(href=self.site_url, rel="alternate")
        fg.link(href=f"{self.site_url}/rss.xml", rel="self")
        fg.description(self.feed_description)
        fg.language("zh-cn")
        fg.lastBuildDate(datetime.now(timezone.utc))
        fg.managingEditor("ai-research@example.com (AI Research Team)")
        fg.webMaster("webmaster@example.com (Webmaster)")

        # å¦‚æœå­˜åœ¨æ—§çš„RSSæ–‡ä»¶ï¼Œå°è¯•åŠ è½½ç°æœ‰æ¡ç›®
        if self.rss_file.exists():
            try:
                # æ³¨æ„ï¼šfeedgenä¸æ”¯æŒç›´æ¥è§£æç°æœ‰RSSï¼Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨å¤„ç†
                # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œåªä¿ç•™åŸºæœ¬çš„feedä¿¡æ¯
                logger.info(f"å‘ç°ç°æœ‰RSSæ–‡ä»¶: {self.rss_file}")
            except Exception as e:
                logger.warning(f"åŠ è½½ç°æœ‰RSSæ–‡ä»¶å¤±è´¥: {e}ï¼Œå°†åˆ›å»ºæ–°çš„feed")

        return fg

    def _add_rss_item(self, fg: FeedGenerator, file_info: Dict, date: datetime) -> bool:
        """ä¸ºRSS feedæ·»åŠ æ–°æ¡ç›®"""
        try:
            category = file_info["category"]
            filename = file_info["filename"]
            papers_count = file_info["papers_count"]
            url = f"{self.site_url}{file_info['url']}"

            # ç”Ÿæˆæ¡ç›®å”¯ä¸€ID
            item_id = f"{self.site_url}/posts/{filename}"

            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒIDçš„æ¡ç›®
            for entry in fg.entry:
                if entry.id() == item_id:
                    logger.debug(f"æ¡ç›®å·²å­˜åœ¨ï¼Œè·³è¿‡: {item_id}")
                    return False

            # åˆ›å»ºæ–°çš„RSSæ¡ç›®
            fe = fg.add_entry()
            fe.id(item_id)
            fe.title(f"{date.strftime('%Y-%m-%d')} {category} Papers ({papers_count}ç¯‡)")
            fe.link(href=url)
            fe.description(f"ä»Šæ—¥{category}é¢†åŸŸç²¾é€‰è®ºæ–‡ {papers_count} ç¯‡ï¼ŒåŒ…å«è¯¦ç»†åˆ†æå’Œå…³é”®æ´å¯Ÿã€‚")

            # ç”Ÿæˆå‘å¸ƒæ—¶é—´ï¼ˆä½¿ç”¨å½“å¤©çš„ä¸­åˆ12ç‚¹ï¼‰
            pub_date = datetime.combine(date, datetime.min.time().replace(hour=12))
            pub_date = pub_date.replace(tzinfo=timezone.utc)
            fe.pubDate(pub_date)

            # æ·»åŠ åˆ†ç±»
            fe.category(category)
            fe.category("AI Research")

            # ç”Ÿæˆå†…å®¹æ‘˜è¦ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
            content_summary = self._generate_content_summary(file_info, papers_count)
            fe.content(content_summary, type="CDATA")

            logger.debug(f"æ·»åŠ RSSæ¡ç›®: {fe.title()}")
            return True

        except Exception as e:
            logger.error(f"æ·»åŠ RSSæ¡ç›®å¤±è´¥: {e}")
            return False

    def _generate_content_summary(self, file_info: Dict, papers_count: int) -> str:
        """ç”ŸæˆRSSæ¡ç›®çš„å†…å®¹æ‘˜è¦"""
        category = file_info["category"]
        date = file_info.get("date", "ä»Šæ—¥")

        summary = f"""
<h2>{category} é¢†åŸŸè®ºæ–‡æ±‡æ€»</h2>
<p>æœ¬æœŸä¸ºæ‚¨ç²¾é€‰äº† {papers_count} ç¯‡ {category} é¢†åŸŸçš„ä¼˜è´¨è®ºæ–‡ï¼Œæ¯ç¯‡éƒ½ç»è¿‡è¯¦ç»†çš„ç»“æ„åŒ–åˆ†æã€‚</p>

<h3>ä¸»è¦å†…å®¹åŒ…æ‹¬ï¼š</h3>
<ul>
    <li>ğŸ“Š é—®é¢˜å®šä¹‰ä¸ç ”ç©¶åŠ¨æœº</li>
    <li>ğŸ” æŠ€æœ¯æ–¹æ¡ˆä¸åˆ›æ–°ç‚¹</li>
    <li>âš¡ å®éªŒéªŒè¯ä¸ç»“æœåˆ†æ</li>
    <li>ğŸ’¡ åº”ç”¨å‰æ™¯ä¸æœªæ¥å±•æœ›</li>
</ul>

<p><a href="{self.site_url}{file_info['url']}">ç‚¹å‡»æŸ¥çœ‹å®Œæ•´åˆ†æ</a></p>

<hr>
<p><em>ç”± Daily Paper Processing System è‡ªåŠ¨ç”Ÿæˆ | æ•°æ®æ¥æº: arXiv</em></p>
"""
        return summary.strip()

    def _limit_feed_items(self, fg: FeedGenerator):
        """é™åˆ¶RSS feedçš„æœ€å¤§æ¡ç›®æ•°"""
        if len(fg.entry) > self.max_items:
            # æŒ‰å‘å¸ƒæ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„æ¡ç›®
            fg.entry.sort(key=lambda e: e.pubDate(), reverse=True)
            fg.entry = fg.entry[: self.max_items]
            logger.info(f"RSSæ¡ç›®å·²é™åˆ¶ä¸ºæœ€æ–° {self.max_items} æ¡")

    def _save_rss_feed(self, fg: FeedGenerator):
        """ä¿å­˜RSS feedåˆ°æ–‡ä»¶"""
        try:
            # ç”ŸæˆRSS XML
            rss_str = fg.rss_str(pretty=True)

            # å†™å…¥æ–‡ä»¶
            with open(self.rss_file, "wb") as f:
                f.write(rss_str)

            logger.info(f"RSSæ–‡ä»¶å·²ä¿å­˜: {self.rss_file}")

        except Exception as e:
            logger.error(f"ä¿å­˜RSSæ–‡ä»¶å¤±è´¥: {e}")
            raise

    def configure_from_config(self, config: Dict[str, Any]):
        """ä»é…ç½®ä¸­æ›´æ–°RSSè®¾ç½®"""
        rss_config = config.get("rss", {})

        if "site_url" in rss_config:
            self.site_url = rss_config["site_url"].rstrip("/")

        if "title" in rss_config:
            self.feed_title = rss_config["title"]

        if "description" in rss_config:
            self.feed_description = rss_config["description"]

        if "max_items" in rss_config:
            self.max_items = rss_config["max_items"]

        logger.info(f"RSSé…ç½®å·²æ›´æ–°: {self.feed_title} @ {self.site_url}")
